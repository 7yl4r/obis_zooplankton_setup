---
title: "Taxonomix Matchup to WoRMs"
author: "Sebastian DiGeronimo"
date: "3/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("readxl")
library("hablar") # might be useful when needing to fix names
library("worrms")

library("tidyverse")
library("ggplot2")
library("ggforce")
library("tibble")
library("tidyr")
library("readr")
library("purrr")
library("dplyr")
library("stringr")
library("forcats")
library("lubridate")
library("glue")
library("fs")
library("geosphere")
library("vroom")
library("plotly")
library("magrittr")

```

```{r create-dir}
# will create a set directory if does not exists
# useful for new projects
source(here::here("scripts","create_dir.R"))

source(here::here("scripts", "taxa_list_check.R"))
```

```{r load-taxa-data}
# ---- load data set ----
file.taxa <- 
    fs::dir_ls(path =  here::here("data", "raw"),
           regexp = "^[^~]*\\.xlsx$") 

# find the number of skips to start of taxa information
skips <-  which(readxl::read_xlsx(file.taxa, range = cell_cols("A"), 
                                  col_names = FALSE ) == "Taxa") - 1

# extract values for calculating individuals per cubic meter
calc <-
    readxl::read_xlsx(
                      file.taxa[1], 
                      n_max = skips, 
                      col_names = c("x1", "x2", "x3")
                      ) %>% 
    select(-x3) %>%
    pivot_wider(#id_col      = x1,
                names_from  = x1,
                values_from = x2
                ) %>%
    janitor::clean_names() %>%
    mutate(
        date_collected = as.Date(as.numeric(date_collected), origin = "1899-12-30"),
        date_analyzed  = as.Date(as.numeric(date_analyzed), origin = "1899-12-30")
    ) %>%
    hablar::retype()

# load the data set
taxa <- readxl::read_xlsx(file.taxa,  
                          skip = skips, 
                          .name_repair = janitor::make_clean_names) %>%
                          mutate(
                              cruise_id = calc$sample_id,
                              .before = everything()
                          ) %>%
                        full_join(x = calc, by = c("sample_id" = "cruise_id")) %>%
                        select(cruise_id = sample_id, everything()) %>%
                        filter(mean > 0)

rm(skips, file.taxa)
```

1. read in new occurrence file
2. read the first 10 rows and transpose to longer
3. determine if the identified species are in the master aphia taxa list, or 
    if need to rerun taxa_match_fix
4. row bind occurrence data with taxa info

```{r}
# TODO: read in all files, joining with scientific names, then add more if they 
# don't exist

taxa_matched_merg <- merge_taxa(taxa) %>%
    relocate(cruise_id, date_collected, site, .before = 1)

file.name <-
    glue(
        "{here::here('data', 'processed')}/
        \b{taxa_matched_merg$cruise_id[1]}_
        \b{taxa_matched_merg$site[1]}_
        \b{taxa_matched_merg$mesh[1]}um_
        \btaxa_merged
        \b{format(Sys.time(), '_%Y%m%d_%H%M%S')}
        \b.csv"
    ) %>%
    str_remove_all("(\\\n\\\b)")

write_csv(
    x = taxa_matched_merg,
    file = file.name,
    na = "")

```

# tried a different database without working
```{r}
# library("taxize")
# 
# 
# 
# cbind(taxa.name, test)
# 
# ?get_tsn
# get_tsn(taxa.name[1:5])
# get_tsn(("Acartia"))
# get_wormsid(test)
# get_wormsid("fish", searchtype = 'common')
# 
# rgbif::name_backbone("Acartia")
# 
# obistools::match_taxa(c("Acartia","Candacia","copepod","Euterpina acuntifrons"), ask = T)
```

```{r}


# obis.taxa <- obistools::match_taxa(taxa.name, ask = T)
# 
# robis::taxon(11676)
# 
# # with this 20 have NA without ability to ask for input
# obis.taxa %>%
#     mutate(taxa.name, .before = 1)
```

