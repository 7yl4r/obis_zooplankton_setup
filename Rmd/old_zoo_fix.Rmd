---
title: "Fix Old Zooplankton Data"
author: "Sebastian DiGeronimo"
date: "2023-01-13"
output: html_document
---
# Load libraries
```{r setup, include=FALSE}
library("tidyverse")
library("fs")
library("magrittr")
library("cli")
library("stringr")
library("glue")
library("readxl")
library("lubridate")
library("readxl")
```

# Files needed:
compiled_zoo_taxonomy_Jaimie_31JAN2018 (1).xlsx
sample-details.csv

In google drive: 
zooplankton data > data > 1_raw > compiled_zoo_taxonomy_Jaimie_31JAN2018 (1).xlsx
zooplankton data > data > 2a_csv > sample-details.csv

Download and place somewhere in project directory
```{r file-paths}
# find location of compiled_zoo_taxonomy_Jaimie_31JAN2018 (1).xlsx
file_location <- fs::dir_ls(here::here(), 
                            regexp = "compiled_zoo_taxonomy_Jaimie_31JAN2018", 
                            recurse = TRUE)


# find location of sample-details.csv
meta_samples_file <- fs::dir_ls(here::here(), 
                                regexp = "sample-details.csv", 
                                recurse = TRUE)

file_location
meta_samples_file
```
# Read sheet names to parse station, month, year, mesh and if duplicate 

Read all sheet names
WS = Western Sambo
LK = Looe Key
MR = Molasses Reef

This is how I extract year, month, location, and mesh
i.e. LK0415200 = station LK, month 04, year 2015 and mesh 200 um

If it contains a 2 at the end then it's a duplicate
i.e. WS04155002

Two sheet names had an extra `0`, so was removed 
```{r parse-meta-from-name}
sheets <-
    readxl::excel_sheets(file_location) %>%
    
    # turn into tibbles
    tibble(sheets = .) %>%
    
    # remove useless sheet names
    filter(!str_detect(sheets, "Samples|PL")) %>%
    
    # parse info
    mutate(
        sheet = if_else(str_detect(sheets, "MR116500"), "MR0116500", sheets),
        sheet = if_else(str_detect(sheets, "WS0117640"), "WS011764", sheet),
        stn   = str_sub(sheet, 1, 2),
        month = str_sub(sheet, 3, 4),
        year  = str_sub(sheet, 5, 6),
        mesh  = str_sub(sheet, 7, 10)  %>% str_remove(., "2$"),
        dup   = if_else(str_detect(sheet, "2$"), "duplicate", "")
    )  %>%
    
    # remove temp column
    select(-sheet) %>%
    arrange(year, month, stn, mesh)

sheets
```

# Load each data sheet
Metadata: first 7 rows
Data: skip first 7 rows
```{r load-species-data}
species <- 
    
    sheets %>%
    
    # add 2 columns and loop through each file to load
    # 1. meta data (includes date and location)
    # 2. data (includes species info)
    mutate(
        # metadata
        meta = map(sheets, 
                   ~ readxl::read_xlsx(file_location, sheet = .,
                                       n_max = 7, col_names = FALSE,
                                       .name_repair = janitor::make_clean_names)),
        # species data
        data = map(sheets, 
                   ~ readxl::read_xlsx(file_location, sheet = ., skip = 7,
                                       .name_repair = janitor::make_clean_names,
                                       na = c("", "#VALUE!")))
    ) %>%

    # extract the data within the list
    unnest(data) 

# show random sample from data
slice_sample(species, n = 10)

# species # full data
```

# Fix rows with NA
```{r fix-na-columns}
# find columns of list that have na's
num_na <- species %>%
    filter(is.na(n_ind_m3)) %>%
    count(sheets)

# determine if NAs for individuals per cubic meter are because:
# 1. there was no volume recorded: occurs when number of NA is bigger than 1
# 2. the specie didn't exist: occurs when only one NA
species <- species %>%
    mutate(
        no_vol = if_else(
            sheets %in% num_na$sheets[num_na$n > 1],
            "no volume recorded", ""
        )
    )
```

# Load meta data
```{r load-metadata}
# load metadata and fix
meta_samples <- 
    meta_samples_file %>%
    read_csv(show_col_types = FALSE,
             name_repair = "unique_quiet") %>%
    mutate(
        month   = format(Date, "%m"),
        year    = format(Date, "%y"),
        day     = format(Date, "%d"),
        .before = Date
    ) %>%
    mutate(
        stn = case_when(
                    str_detect(Station, "Mol") ~ "MR",
                    str_detect(Station, "West") ~ "WS",
                    str_detect(Station, "Loo") ~ "LK",
        ),
        mesh_size_um = strsplit(as.character(`mesh size (um)`), "/"),
        .before = `mesh size (um)`
    ) %>%
    unnest(mesh_size_um) %>%
    mutate(mesh_size_um = str_trim(mesh_size_um)) %>%
    distinct(stn, Date, mesh_size_um, .keep_all = TRUE)

# show sample of data
slice_sample(meta_samples, n = 10)
```

# Add meta to species data
```{r add-meta-to-merge}
# merge metadata with zoo data
# this combines month, year, station and mesh 
species_meta <- 
    species %>%
    left_join(
        meta_samples,
        by = c("year" = "year",
               "month" = "month",
               "stn" = "stn",
               "mesh" = "mesh_size_um")
    ) %>%
    select(
        -c(`Tow time (min)`:Comment, `flowmeter in`, ...1,
           `mesh size (um)`, Station)
    ) %>%
    relocate(
        year, month, day, Date, `Local time (EST)`, `LON in`, `LAT in`, 
        .before = month
    ) %>%
    relocate(dup, meta, .after = no_vol) %>%
    relocate(n_ind_m3, .after = clasification)

slice_sample(species_meta, n = 10) 
```
```{r save-data}
write_csv(species,
          file = here::here(dirname(file_location), "zoo_compiled.csv"),
          na   = "")

write_csv(species_meta,
          file = here::here(dirname(file_location), "zoo_compiled_with_meta.csv"),
          na = "")
```

