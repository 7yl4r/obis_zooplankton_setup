---
title: "Combine Zooplankton Logsheet"
author: "Sebastian DiGeronimo"
date: '2022-07-08'
output: html_document
---

# Load Packages
This loads any packages that are not contained in the .Rprofile.
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
librarian::shelf(
    readxl, hablar, worrms, ggforce, geosphere, vroom, plotly,
    quiet = TRUE
    )
```

# Load cruise metadata files from `data/metadata/` 
1. Parse all file paths
- Will ignore files with `~$` in front because these are usually temporary files that are opened
2. Remove files that would not contain zooplankton metadata
3. Loop through each file and look for sheet with `zooplankton` in the name 
```{r read-sheets, include=FALSE}
# select all cruise files
meta <- 
    fs::dir_ls(here::here("data", "metadata", "cruise_logsheets"), recurse = T,
               regexp = "^[^~]*\\.(xlsx)$")  %>%
    tibble(file = .) %>%
    
    # filter for only fknms files
    filter(!str_detect(file, 
                       c("All_cruise|BB3|Digna|Schedule|Kelble"))
           ) %>%
    
    # column for only filename
    mutate(
        base = basename(file)
    )

# read all files for sheet names that match zooplankton and Sheet2
temp <- meta %>%
    mutate(sheets = map(.x = file, ~ readxl::excel_sheets(.x))) %>%
    unnest(sheets) %>%
    group_by(base) %>%
    
    # filter for sheets with zooplankton
    filter(str_detect(sheets, "zooplankton|Sheet2")) %>%
    ungroup() %>%
    select(-file)

# join filenames with sheet names, any NAs will be figured out later
meta <-
    left_join(meta, temp, by = "base") %>% 
    filter(!is.na(sheets)) %>%
    group_by(base) %>%
    mutate(
        info = map2(.x = file, .y = sheets, function(.x, .y) {
            print(basename(.x))
            
            # identify cruise ID line
            cruise_id <-
            tryCatch({
                id_skip <- 
                    readxl::read_xlsx(
                       .x,
                        range = cell_cols("A"),
                        col_names = FALSE,
                        sheet = .y
                        ) %>%
                    pull(1)  %>%
                    str_which("Cruise")
                
                # extract cruise ID 
                readxl::read_xlsx(
                    path = .x,
                    skip = id_skip - 1,
                    sheet = .y,
                    col_names = F,
                    n_max = 1
                ) %>%
                    pivot_wider(names_from = `...1`, values_from = `...2`)
                
            }, error = function(e) {
                message("Will need to drop later.")
                tibble(Cruise = NA_character_)
            })
            
            # find number of rows to skip to get to metadata
            skips <- readxl::read_xlsx(
                       .x,
                        range = cell_cols("A"),
                        col_names = FALSE,
                        sheet = .y
                        ) %>%
            pull(1)  %>%
            str_which("(?i)zooplankton sampling")
    
            # if skips can't find a number, will make NA
            if (identical(skips, integer(0))) skips <- NA_integer_

            cruise_id <- 
                select(cruise_id, cruise_id = Cruise) %>%
                add_column(skips = skips)
        })) %>%
    unnest(info) %>%
    drop_na(skips)
    

rm(temp)
```

```{r load-logsheets}
meta <- meta %>%
    # slice(n = 1) %>%
    mutate(
        data = pmap(
            .l = list(.x = file, .y = skips, .z = sheets, .c = cruise_id), 
            function(.x, .y, .z, .c) {
                cli_alert_info(.c)
                
                # read sheets
                temp <- readxl::read_xlsx(
                        .x,
                        sheet = .z,
                        skip = .y,
                        .name_repair = janitor::make_clean_names,
                        na = c("skip", "Did not collect", "not recorded")
                    ) %>%
                
                    # remove rows that are fully empty
                    janitor::remove_empty(which = "rows") %>%
                    
                    # fill station names down if not there
                    tidyr::fill(station) %>%
                    
                    # drop rows when flowmeter_out = NA
                    drop_na(flowmeter_out) %>%
                    
                    # fill down if lat, lon, date, or time is not there
                    tidyr::fill(contains(c("lat", "lon", "date", "time"))) %>%
                
                mutate(
                    # convert time if labeled as time_gmt if needed
                    try(across(contains(c("time_gmt")),
                           list(time_gmt = ~ hms::as_hms(
                               format(.x, format = "%H:%M:%S",
                                        tz = "utc")
                           )),
                           .names = "{.fn}"), silent = T),
                    
                    # convert time_gmt to date_time if possible with date and 
                    # time_gmt columns
                    try(across(contains(c("time_gmt")),
                           list(date_time = ~ ymd_hms(paste(date, .x),tz = "utc")),

                           .names = "{.fn}"), silent = T),
                    .after = 4
                )
                
                # convert lat_in and/or lon_in from deg minutes to decimal 
                # degrees if type is str
                if (is.character(temp$lat_in) | is.character(temp$lon_in)) {
                    message("Converting lat and lon into decimal degrees.\n")
                    temp %<>%
                        add_column(
                            with(.,
                                parzer::parse_lon_lat(lon_in, lat_in)), 
                            .after = "lon_in"
                            ) %>%
                        select(-lon_in, -lat_in) %>%
                        rename(lon_in = lon, lat_in = lat)
    
                }
                
                # change name of x to notes if exists
                if (!is.null(temp)) temp <- rename(temp, any_of(c(notes = "x")))
                
                # check if can retype columns to chr, num, or date     
                temp <- tryCatch({
                    
                    temp <- hablar::retype(temp,-time_gmt)
                }, error = function(e) {
                    message("Doesn't have a time_gmt column. Returning as is.\n")
                    temp
                })
                
                # specify what to convert types to merge later
                 temp <- hablar::convert(temp,
                                         chr(ship_speed_knots, split_size,
                                             station, mesh_size_um))
        }
            )
    )  %>%
    
    # filter for sheets without any information
    mutate(data_exists = map(.x = data , ~ if_else(nrow(.x) > 0, 1, 0))  %>%
    unlist()) 

```

# Keep record of files that have no data because either didn't collect or didn't write down
```{r filter-no-data}
no_data <- meta %>%
    filter(data_exists == 0)

meta <- meta %>%
    filter(data_exists > 0) %>%
    select(-data_exists) %>%
    unnest(data) %>%
    select(-file, -sheets, -skips, -local_time_est, file = base) %>%
    separate_rows(mesh_size_um, sep = "/") %>%
    mutate(
        mesh_size_um = str_trim(mesh_size_um), 
        mesh_size_um = retype(mesh_size_um),
        # file = str_remove(file,pattern = "\\.\\d{1,3}$")
        # mesh_size_um = strsplit(as.character(mesh_size_um), "/")
        ship_speed_knots = str_remove_all(ship_speed_knots, "~"),
        file = tools::file_path_sans_ext(file)
    ) %>%
      arrange(date)
```

# Save merged metadata
```{r save}
# ---- write metadata to file ----
if (FALSE) {
    write_csv(meta,
              here::here("data", "metadata", "cruise_loghseets", 
                         glue("meta_combined", 
                              format(Sys.time(), '_%Y%m%d_%H%M%S'),
                              ".csv")
                         ),
              na = ""
              )
}
```

