---
title: "Combine Zooplankton Logsheet"
author: "Sebastian DiGeronimo"
date: '2022-07-08'
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library("readxl")
library("hablar") # might be useful when needing to fix names
library("worrms")

library("ggplot2")
library("tibble")
library("tidyr")
library("readr")
library("purrr")
library("dplyr")
library("stringr")
library("forcats")
library("lubridate")
library("glue")
library("fs")
library("magrittr")
library("broom") # optional

library("tidyverse")
library("ggforce")
library("geosphere")
library("vroom")
library("plotly")
```

Workflow:
https://github.com/ioos/bio_data_guide/tree/main/OBIS_data_tiers
Needed: 3 things
    1. Event
    2. Occurances
    3. Measurement of Fact (MOF)



1. Read and format metadata spreadsheets
    - convert to DarwinCore format 
    
```{r}
files <- fs::dir_ls(here::here("data", "metadata"), recurse = T,
           regexp = "^[^~]*\\.(xlsx)$") 
files <- files[!grepl("BB3|Digna|Schedule|Kelble", files)][-1]

for (i in seq(files)) {
# for (i in 2) {
    print(basename(files[i]))
    temp_sht <- readxl::excel_sheets(files[i])
    
    # ---- detect if sheets contain zooplankton ----
    # reduces the amount of opening sheets of a file if one is named zooplankton
    # if not, will try all of them
    dect <- any(str_detect(temp_sht, "zooplankton"))
    
    if (isTRUE(dect)) {
        temp_sht <- "zooplankton"
    }
    
    rm(dect)
    
    # ---- open file and read sheet ----
    for (j in seq(temp_sht)) {
        
         cruise_id <-
            tryCatch({
                id_skip <- which(
                    readxl::read_xlsx(
                        files[i],
                        range = cell_cols("A"),
                        col_names = FALSE,
                        sheet = temp_sht[j]
                    ) == "Cruise"
                ) 
                    
                readxl::read_xlsx(
                    path = files[i],
                    skip = id_skip - 1,
                    sheet = temp_sht[j],
                    col_names = F,
                    n_max = 1
                ) %>%
                    pivot_wider(names_from = `...1`, values_from = `...2`)
                
            }, warning = function(w) {
                message(sprintf("Warning in %s: %s", deparse(w[["call"]]), w[["message"]]))
                
            }, error = function(e) {
                message(sprintf("Error in %s: %s", deparse(e[["call"]]), e[["message"]]))
                tibble(Cruise = NA_character_)
            })
        
        
        skips <-
            tryCatch({
                which(
                    readxl::read_xlsx(
                        files[i],
                        range = cell_cols("A"),
                        col_names = FALSE,
                        sheet = temp_sht[j]
                    ) == "ZOOPLANKTON SAMPLING"
                )
            }, warning = function(w) {
                message(sprintf("Warning in %s: %s", deparse(w[["call"]]), w[["message"]]))
                
            }, error = function(e) {
                message(sprintf("Error in %s: %s", deparse(e[["call"]]), e[["message"]]))
                integer()
            }, finally = {
                
            })
        
        
        if (!is_empty(skips)) {
            temp <-
                readxl::read_xlsx(
                    files[i],
                    sheet = temp_sht[j],
                    skip = skips,
                    .name_repair = janitor::make_clean_names,
                    na = c("skip", "Did not collect", "not recorded")
                ) %>%
                janitor::remove_empty(which = "rows") %>%
                tidyr::fill(station) %>%
                drop_na(flowmeter_out) %>%
                tidyr::fill(contains(c("lat", "lon", "date", "time"))) %>%
                mutate(
                    try(across(contains(c("time_gmt")),
                           list(time_gmt = ~ hms::as_hms(
                               format(.x, format = "%H:%M:%S",
                                        tz = "utc")
                           )),
                           .names = "{.fn}"), silent = T),
                    try(across(contains(c("time_gmt")),
                           list(date_time = ~ ymd_hms(paste(date, .x),tz = "utc")),

                           .names = "{.fn}"), silent = T),
                    .after = 4
                ) %>%
                mutate(
                    cruise_id = as.character(cruise_id$Cruise),
                    .before = everything()
                )

            if (is.character(temp$lat_in) | is.character(temp$lon_in)) {
                temp %<>%
                    separate(lat_in, into = c("latdeg", "latmin"), " ") %>%
                    separate(lon_in, into = c("londeg", "lonmin"), " ") %>%
                    mutate(
                        across(latdeg:lonmin, as.numeric),
                        lat_in = latdeg + (latmin / 60),
                        lon_in = -(londeg + (lonmin / 60)),
                        .before = latdeg
                    ) %>%
                    select(-(latdeg:lonmin))
            }

            temp <- tryCatch({
                hablar::retype(temp,-time_gmt)
            }, error = function(e) {
                # message(sprintf("Error in %s: %s", deparse(e[["call"]]), e[["message"]]))
                message("Doesn't a time_gmt column. Returning as is.")
                temp
            })

            
            if (nrow(temp) == 0) temp <- NULL
            
            do.call("<-", list(tools::file_path_sans_ext(basename(files[i])), temp))
            message("SUCESSS")
            next
        } else {
            message(paste0(
                "Might not be this sheet:\n",
                tools::file_path_sans_ext(basename(files[i])),
                ":  ",
                temp_sht[j]
            ))
        }
        
    }
}


rm(i, j, skips, temp_sht, cruise_id)
rm(list = names(which(sapply(
    globalenv(), is.null)))) # or .GlobalEnv
```

Files without info:
October 2017
March 2018
April 2018
April 2021
April 2019

```{r}
meta_list <- ls()[str_detect(ls(),"fknms")]

meta_full <- mget(meta_list) %>%
     discard(function(x) is.null(x)) 

# see where issue will lie when joining
janitor::compare_df_cols(meta_full,
                         return = "match")

# test1 <- 
     # reduce(test[c(1:6,8:12)], full_join )

meta_full$`fknms_logsheet_July 2016_Hepner` <- meta_full$`fknms_logsheet_July 2016_Hepner` %>%
    mutate(date_time = NA_POSIXct_, .after = local_time_est) %>%
    rename(time_gmt = local_time_est)


meta_full <- meta_full %>%
    map(.x, .f=~select(.x, 1:16))

meta_df <-
    do.call(rbind.data.frame, meta_full)   %>%
    rownames_to_column("file")  %>%
    mutate(
    file = str_remove(file,pattern = "\\.\\d{1,3}$"),
    mesh_size_um = strsplit(as.character(mesh_size_um), "/"),
    ship_speed_knots = str_remove_all(ship_speed_knots, "~"),
    # date_time = format_ISO8601(date_time),
    ) %>%
      unnest(mesh_size_um) %>%
    mutate(
        mesh_size_um = str_trim(mesh_size_um)
    ) %>%
    arrange(date)

rm(list = meta_list)
```

```{r save}
# ---- write metadata to file ----
write_csv(meta_df,
              paste0(
                  here::here("data", "metadata", "meta_combined"),
                  format(Sys.time(), '_%Y%m%d_%H%M%S'),
                  ".csv"
              ))
```

```{r}
# dat2 <- tibble::tribble(
#     ~cruiseIDs, ~start_date,
#      "SV18067", "zoo",
#     "SV18173", "zoo", 
#     "WS17170", "zoo", 
#     "WS17275", "zoo",
#     "WS18008", "zoo",
#     "WS18120", "zoo",
#     "WS18285", "zoo",
#     "WS18351", "zoo",
#     "WS19028", "zoo",
#     "WS19210", "zoo",
#     "WS19266", "zoo",
#     "WS19322", "zoo",
#     "WS20006", "zoo",
#     "WS20230", "zoo",
#     "WS20342", "zoo",
#     # "(blank)"
#     )
# 
# dat <- tibble::tribble(
#     ~Cruise.ID,  ~Start.Date,
#      "WS17086",  "3/27/2017",
#      "WS17170",  "6/19/2017",
#      "WS17282",  "10/9/2017",
#      "WS18008",   "1/8/2018",
#      "WS18067",   "3/8/2018",
#      "SAV1803",  "3/10/2018",
#      "WS18120",  "4/30/2018",
#     "SAV18173",  "6/22/2018",
#      "WS18218",   "8/6/2018",
#      "WS18285", "10/12/2018",
#      "WS18351", "12/17/2018",
#      "WS19028",  "1/28/2019",
#      "WS19119",  "4/29/2019",
#      "WS19210",  "7/29/2019",
#      "WS19266",  "9/23/2019",
#      "WS19322", "11/18/2019",
#      "WS20006",   "1/6/2020",
#      "WS20231",  "8/19/2020",
#      "WS20279",  "10/5/2020",
#      "WS20342",  "12/7/2020",
#      "WS21032",   "2/1/2021"
#     )
# full_join(dat, dat2, by = c("Cruise.ID" = "cruiseIDs")) %>%
#     write_csv(file = "../data/cruise_id_merged.csv")
```

