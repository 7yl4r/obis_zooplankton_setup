---
title: "Zooplankton Data to OBIS Format"
author: "Sebastian DiGeronimo"
date: '2022-07-08'
output: html_document
---

```{r setup}
root <- rprojroot::find_rstudio_root_file()
knitr::opts_chunk$set(echo = TRUE)
library("readxl")
library("hablar") # might be useful when needing to fix names
library("worrms")

library("ggplot2")
library("tibble")
library("tidyr")
library("readr")
library("purrr")
library("dplyr")
library("stringr")
library("forcats")
library("lubridate")
library("glue")
library("fs")
library("magrittr")
library("broom") # optional

library("tidyverse")
library("ggforce")
library("geosphere")
library("vroom")
library("plotly")
```

Workflow:
https://github.com/ioos/bio_data_guide/tree/main/OBIS_data_tiers
Needed: 3 things
    1. Event
    2. Occurances
    3. Measurement of Fact (MOF)



1. Read and format metadata spreadsheets
    - convert to DarwinCore format 
    
```{r}
root <- rprojroot::find_rstudio_root_file()
files <- fs::dir_ls(paste0(root,"/data/metadata/"), recurse = T,
           regexp = "^[^~]*\\.(xlsx|csv)$") 
files <- files[!grepl("BB3|Digna|Schedule|Kelble", files)][-1]

for (i in seq(files)) {
# for (i in 1) {
    print(basename(files[i]))
    temp_sht <- readxl::excel_sheets(files[i])
    
    # ---- detect if sheets contain zooplankton ----
    # reduces the amount of opening sheets of a file if one is named zooplankton
    # if not, will try all of them
    dect <- any(str_detect(temp_sht, "zooplankton"))
    
    if (isTRUE(dect)) {
        temp_sht <- "zooplankton"
    }
    
    rm(dect)
    
    # ---- open file and read sheet ----
    for (j in seq(temp_sht)) {
        skips <-
            tryCatch({
                which(
                    readxl::read_xlsx(
                        files[i],
                        range = cell_cols("A"),
                        col_names = FALSE,
                        sheet = temp_sht[j]
                    ) == "ZOOPLANKTON SAMPLING"
                )
            }, warning = function(w) {
                message(sprintf("Warning in %s: %s", deparse(w[["call"]]), w[["message"]]))
                
            }, error = function(e) {
                message(sprintf("Error in %s: %s", deparse(e[["call"]]), e[["message"]]))
                integer()
            }, finally = {
                
            })
        
        
        if (!is_empty(skips)) {
            temp <-
                readxl::read_xlsx(
                    files[i],
                    sheet = temp_sht[j],
                    skip = skips,
                    .name_repair = janitor::make_clean_names,
                    na = c("skip", "Did not collect", "not recorded")
                ) %>%
                janitor::remove_empty(which = "rows") %>%
                tidyr::fill(station) %>%
                drop_na(flowmeter_out) %>%
                tidyr::fill(contains(c("lat", "lon", "date", "time"))) %>%
                mutate(
                    try(across(contains(c("time_gmt")),
                           list(time_gmt = ~ hms::as_hms(
                               format(.x, format = "%H:%M:%S",
                                        tz = "utc")
                           )),
                           .names = "{.fn}"), silent = T),
                    try(across(contains(c("time_gmt")),
                           list(date_time = ~ ymd_hms(paste(date, .x),tz = "utc")),

                           .names = "{.fn}"), silent = T),
                    .after = 4
                )

            if (is.character(temp$lat_in) | is.character(temp$lon_in)) {
                temp %<>%
                    separate(lat_in, into = c("latdeg", "latmin"), " ") %>%
                    separate(lon_in, into = c("londeg", "lonmin"), " ") %>%
                    mutate(
                        across(latdeg:lonmin, as.numeric),
                        lat_in = latdeg + (latmin / 60),
                        lon_in = -(londeg + (lonmin / 60)),
                        .before = latdeg
                    ) %>%
                    select(-(latdeg:lonmin))
            }

            temp <- tryCatch({
                hablar::retype(temp,-time_gmt)
            }, error = function(e) {
                message(sprintf("Error in %s: %s", deparse(e[["call"]]), e[["message"]]))
                temp
            })

            
            if (nrow(temp) == 0) temp <- NULL
            
            do.call("<-", list(tools::file_path_sans_ext(basename(files[i])), temp))
            message("SUCESSS")
            next
        } else {
            message(paste0(
                "Might not be this one:\n",
                tools::file_path_sans_ext(basename(files[i]))
            ))
        }
        
    }
}


rm(i, j, skips, temp_sht)
rm(list = names(which(sapply(
    globalenv(), is.null)))) # or .GlobalEnv

```

Files without info:
October 2017
March 2018
April 2018
April 2021
April 2019

```{r}
meta_list <- ls()[str_detect(ls(),"fknms")]



meta_full <- mget(meta_list) %>%
     discard(function(x) is.null(x)) 

# see where issue will lie when joining
janitor::compare_df_cols(meta_full,
                         return = "match")

# test1 <- 
     # reduce(test[c(1:6,8:12)], full_join )

meta_full$`fknms_logsheet_July 2016_Hepner` <- meta_full$`fknms_logsheet_July 2016_Hepner` %>%
    mutate(date_time = NA) %>%
    rename(time_gmt = local_time_est)


meta_full <- meta_full %>%
    map(.x, .f=~select(.x, 1:15))

meta_df <-
    do.call(rbind.data.frame, meta_full)   %>%
    rownames_to_column("file")  %>%
    mutate(
    file = str_remove(file,pattern = "\\.\\d{1,3}$"),
    mesh_size_um = strsplit(as.character(mesh_size_um), "/"),
    ship_speed_knots = str_remove_all(ship_speed_knots, "~"),
    # date_time = format_ISO8601(date_time),
    ) %>%
      unnest(mesh_size_um) %>%
    mutate(
        mesh_size_um = str_trim(mesh_size_um)
    ) %>%
    arrange(date)

rm(list = meta_list)
```

```{r save}
# ---- write metadata to file ----
write_csv(meta_df,
              paste0(
                  root,
                  "/data/metadata/meta_combined",
                  format(Sys.time(), '_%Y%m%d_%H%M%S'),
                  ".csv"
              ))
```

