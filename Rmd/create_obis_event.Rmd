---
title: "OBIS Event Creations"
author: "Sebastian DiGeronimo"
date: '2022-09-02'
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---
TODO: check how to save UTF-8 encoding on csv files 
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library("readxl")
library("hablar") # might be useful when needing to fix names
library("worrms")
library("here")
library("ggplot2")
library("tibble")
library("tidyr")
library("readr")
library("purrr")
library("dplyr")
library("stringr")
library("forcats")
library("lubridate")
library("glue")
library("fs")
library("magrittr")
library("broom") # optional

library("tidyverse")
# library("ggforce")
# library("geosphere")
# library("vroom")
# library("plotly")

# obistools::event_fields()
# source(here::here("scripts","log_file_changes.R"))
# startup("log_edits2")
# log_add()

# ---- recorded by info ----
nlf       <- "Natalia Lopez Figueroa"
orcid_nat <- "https://orcid.org/0000-0002-7527-0481"

# ---- set variables for calculation ----
inpeller <- 26873 / 999999 # starting oct 2022 for 200/500 um
# net_area <- pi * 0.5^2

# TODO: check this equation ---------------------------------------------------
which_one <- "nat"
equation_zoo <- switch(
    which_one,
    "nat"    = expression(dillution_factor * mean * 2 ^ (splits_analyzed)),
    "jamie"  = expression(dillution * mean * splits_analyzed / pipette_vol_m_l),
    "jamie2" = expression(dillution * mean)
)
rm(which_one)
```


# Load functions if not in .Rprofile and already attached to the searchpath
```{r load-functions}
if (!rlang::is_attached('my_funcs')) { 
    cli_alert_info(
        c("Attaching project functions to the {.code searchpath} as ",
          "{.code my_funcs}."))
    
    # source scripts with functions in new environment
    my_funcs <- new.env()
    
    # create directory structure if does not exists and create tree map
    source(here::here("scripts","create_dir.R"), local = my_funcs)
    # copy files from a cloud service
    source(here::here("scripts", "copy_files_from_cloud.R"), local = my_funcs)
    # loading check for taxa
    source(here::here("scripts", "taxa_list_check.R"), local = my_funcs)
    
    attach(my_funcs)
}
```

Workflow:
<https://github.com/ioos/bio_data_guide/tree/main/OBIS_data_tiers>
Needed: 3 things 1. Event 2. Occurances 3. Measurement of Fact (MOF)

1.  Read and format metadata spreadsheets
    -   convert to DarwinCore format

MOF = measurement of fact

Event - where/when took place

Occurrence - species info, presence/absence Occurrence MOF - quantity,
other info to measure them

MOF - environmental quantities measured

# not finished yet

occurrence = institution_code = "USF_IMaRS" 
collection_code = "compiled_zoo_taxonomy_nlf" 
catalog_number = "20yy_mm_dd" 
occurrenceID = (unique identifier) 
joining of <urn:catalog> institution code
collection_code catalog_number row number 
join by : 
eventDate = date_time 
decimalLongitude = lon_in 
decimalLatitude = lat_in
scientificName = natalia spreadsheet 
scientificNameID = "TODO: worms lookup", #taxonomy_df["classification"],

occurence = basisOfRecord = "HumanObservation", 
collectionCode = collection_code, 
catalogNumber = catalog_number, 
occurrenceStatus = "present", 
institutionCode = institution_code

extra-stuff mesh_size flowmeter in flowmeter out ship speed inpeller
constant distnace tow speed formalin vol filtered

# Load data for OBIS conversion
```{r load-data}
# ---- load aphiaid ----
aphia_id <-
    fs::dir_ls(path = here::here("data", "metadata", "aphia_id"),
               regexp = "^[^~]*(aphia)+.*\\.csv$") %>%
    last_mod(.) %>%
    read_csv(show_col_types = FALSE) %>%
    mutate(
        aphiaID = if_else(!is.na(scientificNameID), 
                          str_split(scientificNameID, ":", simplify = T)[, 5],
                          NA_character_) %>%
                          as.numeric(.),
        info = map(aphiaID, ~ worrms::wm_record(.x))
    ) %>%
    unnest(info, names_repair = janitor::make_clean_names) %>%
    select(!contains("_2"), -c(1:6)) 

# ---- load metadata ----
meta_df <-
    fs::dir_ls(path = here::here("data", "metadata"),
               regexp = "^[^~]*(meta_)+.*\\.csv$") %>%
    last_mod(.) %>%
    read_csv(show_col_types = FALSE) %>%
    
    # this is when Natalia LF started analysis
    filter(date >= date("2017-06-18")) %>%
    
    mutate(locationID      = case_when(
                str_detect(station, "Mol") ~ "MR",
                str_detect(station, "Loo") ~ "LK",
                str_detect(station, "West") ~ "WS",
                str_detect(station, "9B") ~ "9B",
                TRUE ~ station), 
           .after = station) %>%
    mutate(
        # Note: flowmeter is MF315
        net_size            = 0.5,
        net_area            = pi * 0.5^2,
        distance_m_2        = (flowmeter_out - flowmeter_in) * inpeller_constant,
        tow_speed_m_sec     = distance_m_2 / (tow_time_min * 60),
        # tow_speed_cm_sec     = distance_m_2 * 100 / (tow_time_min * 60),
        volume_filt_cubic_m = net_area/4 * distance_m_2,
        split_size          = map(split_size, function(x) {
                                    out <- tryCatch({
                                    eval(parse(text = x))}, 
                                    error = function(e) {NA_integer_})}) %>% 
                              unlist(.)
       ) 

# ---- load zooplankton data ----
taxa_files <-
    fs::dir_ls(path = here::here("data", "processed"),
               regexp = "all_merged_processed") %>%
    
    # use all files or only most recent
    last_mod(., check = TRUE) %>%
    map_dfr(~ read_csv(., show_col_types = FALSE)) %>%
    mutate(
        # fix some cruise ID from data spreadsheets
        cruise_id = case_when(
            str_detect(cruise_id, "006") ~ "WS20006",
            str_detect(cruise_id, "WS118218") ~ "WS18218",
            str_detect(cruise_id, "WS18224") ~ "WS18218",
            str_detect(cruise_id, "WS18284") ~ "WS18285",
            # str_detect(cruise_id, "") ~ "", # incase other become problematic
            TRUE ~ cruise_id
        ),
    site = str_replace(site, "MK", "MR"),
    lifeStage = case_when(
        is.na(lifeStage) ~ "adult",
        TRUE ~ lifeStage)
) %>%
  select(-mean_ind_dil_factor)

# ---- merge metadata and taxa data ----
taxa_matched_merg <-
    taxa_files %>%
    left_join(meta_df, 
              by = c("cruise_id", "site" = "locationID", 
                     "mesh" = "mesh_size_um")) %>%
    mutate(
        # split_amount = 0.5, # splits from cruise
        splits_analyzed   = case_when(
            is.na(splits_analyzed) ~ 0,
            TRUE ~ splits_analyzed
            ),
        number_ind_sample = eval(equation_zoo),
        ind_m3            = number_ind_sample / volume_filt_cubic_m,
        
        # get aphia ID from end of scientificNameID
        aphiaID = if_else(!is.na(scientificNameID), 
                          str_split(scientificNameID, ":", simplify = T)[, 5],
                          NA_character_) %>%
                          as.numeric(.),
        # info = map(aphiaID, ~ worrms::wm_record(.x))
        ) %>%
    left_join(., 
              aphia_id,
              by = c("aphiaID" = "aphia_id"))
```

# Occurrence Bare Minimum example
set to `TRUE` if want to run
```{r obis-file}
if (FALSE) {
   data.table::data.table(
          occurrenceID = c("my-dataset-0001c29"),
       decimalLatitude = c(-87.7575),
      decimalLongitude = c(24.4727),
        scientificName = c("Sparisoma aurofrenatum"),
      scientificNameID = c("urn:lsid:ipni.org:names:37829-1:1.3"),
      occurrenceStatus = c("present"),
         basisOfRecord = c("HumanObservation"),
             datasetID = c("my-dataset-tylar-2020-01-08-123456"),
             eventDate = c("2010-01-03T13:44Z")
    )
}
```

# Record Level Info
```{r record-level}
taxa_original <- taxa_matched_merg
taxa_matched_merg <-
    taxa_original  %>%
    mutate(
        type                = "Event",
        modified            = Sys.Date(),
        language            = "en",
        license             = "http://creativecommons.org/publicdomain/zero/1.0/legalcode",
        institutionCode     = "USF_IMaRS",
        parentEventID       = "IMaRS_MBON_zooplankton",
        datasetName         = "MBON Florida Keys National Marine Sanctuary",
        basisOfRecord       = "PreservedSpecimen", # "HumanObservation",
        informationWithheld = "collector identities withheld because changed frequently",
        recordedBy          = nlf,
        recordedByID        = orcid_nat,
    ) 

rcd_lvl <- taxa_matched_merg %>%
    distinct()

rm(nlf, orcid_nat)
```

# Event Level Info
```{r event}
event <-
    # meta_df %>%
    # TODO: should probably be just meta_df
    taxa_matched_merg  %>%
    dplyr::transmute(
        cruise_id, mesh, parentEventID, type, modified, license, 
        institutionCode, datasetName, basisOfRecord, informationWithheld,
        recordedBy, recordedByID, language,
        # catalogNumber   = row_number(),
        locationID = site,
        # parentEventID      = "IMaRS_MBON_zooplankton",
        datasetID          = glue("{parentEventID}:{cruise_id}"),
        eventDateTime      = format(date_time, "%Y-%m-%dT%H:%m:%S%z"),
        # eventID - something like cruiseID:stationID:meshsize
        # {{mbon} : cruise} : stn : mesh : date_time
        eventID            = glue(
                        "{datasetID}:stn{locationID}:{mesh}um:{eventDateTime}"
        )  %>% str_remove("\\+0000"),
        fieldNumber        = glue("{cruise_id}-{station}-{mesh}"),
        eventDate          = date(date_time),
        eventTime          = format(date_time, "%H:%m:%S%z"),
        year               = year(date_time),
        month              = month(date_time),
        day                = day(date_time),
        # samplingProtocol = paste(mesh_size_um, "mesh size (um)"),
        samplingProtocol   = glue(
            "{mesh} mesh size (um) - bongo nets | http://drs.nio.org/drs/handle/2264/95"
        ),
        
        # TODO: habitat NERC vocab
        habitat            = "near reef",
        sampleSizeValue    = volume_filt_cubic_m,
        sampleSizeUnit     = "Volume per cubic metre of filtered seawater",
        samplingEffort     = str_c(tow_time_min, "minutes", sep = " ")
    ) %>%
     distinct() %>%
     mutate(
         # TODO: save for the end when combining all same sizes together
         catalogNumber   = row_number(),
         .before = everything()
     )
```

# Loctation Level Info:
```{r location}
location <-
    taxa_matched_merg %>%
    left_join(event, by = c("cruise_id", "site" = "locationID", "mesh")) %>%
    dplyr::transmute(
        eventID,
        decimalLatitude   = lat_in,
        decimalLongitude  = lon_in,
        higherGeographyID = case_when(
            str_detect(site, "MR|LK|WS|9B") ~ "http://vocab.getty.edu/tgn/7030258",
            str_detect(site, "5") ~ "http://vocab.getty.edu/tgn/1101513",
            TRUE ~ "Not Found"
        ),
        higherGeography   = "North America | United States | Florida",
        continent         = "North America",
        country           = "United States",
        countryCode       = "US",
        stateProvince     = "Florida",
        geodeticDatum     = "EPSG:4326",
        georeferencedBy   = "NOAA AOML | USF IMaRS | RSMAS R/V Walton Smith"
    ) %>%
    distinct()

left_join(
    event, location
)

```

Ocurrence Level Info:
```{r occurence}
occur <-
    taxa_matched_merg %>%
    left_join(event, 
              by = c("cruise_id", "site" = "locationID", "mesh", "recordedBy", 
                     "recordedByID", "basisOfRecord")
              ) %>%
    dplyr::transmute(
        eventID, 
        occurrenceID             = glue("{eventID}:{aphiaID}:{lifeStage}"),
        scientificName,
        across(kingdom:genus),
        taxonRank = rank,
        taxonID = taxon_rank_id,
        recordedBy,
        recordedByID,
        dateIdentified           = date_analyzed,
        # IDk which of these is accurate
        individualCount          = number_ind_sample,
        organismQuantity         = ind_m3,
        organismQuantityType     = "Individuals per cubic metre",
        # or
        # measurementType          = "Number per cubic metre",
        # MOF? should also include ind/sample?
        measurementUnitID        = "http://vocab.nerc.ac.uk/collection/P06/current/UPMM/",
        # MOF?
        
        # TODO: check this information ----
        lifeStage,
        establishmentMeans       = "native | uncertain",
        occurrenceStatus         = "present",
        preparations             = "formalin before analysis | ethanol after analysis",
        scientificNameID,
        # like urn:lsid:ipni.org:names:37829-1:1.3
        basisOfRecord,
        datasetID,
        eventDate                = date(date_time),
        identificationReferences = "WoRMS",
        verbatimIdentification   = taxa_orig,
        georeferenceVerificationStatusProperty = "verified by contributor",
        dispostion = "in collection"
    )

```
# Mearuement or Fact example
```{r MoF-example}
# MoF https://github.com/ioos/bio_data_guide/blob/main/datasets/WBTS_MBON/IOOS%20DMAC%20DataToDwC_Notebook_event.ipynb
if (FALSE) {
# ---- Measurement or Fact ----

tibble::tribble(
              ~Origin.Term,                                       ~measurementTypeID,       ~URI,
                "Net_Type",                                             "plankton net",       "22",
               "Mesh_Size",                                   "Sampling net mesh size", "Q0100015",
               "NET_DEPTH",       "Depth (spatial coordinate) of sampling event start", "DXPHPRST",
                 "COMMENT",            "N/A (mapped to measurementRemark field above)",      "N/A",
       "Plankton_Net_Area",                    "Sampling device aperture surface area", "Q0100017",
         "Volume_Filtered",                                                   "Volume",      "VOL",
            "Sample_Split", "N/A (information added to measurementRemark field above)",      "N/A",
       # "Sample_Dry_Weight",                                       "Dry weight biomass", "ODRYBM01",
                # "DW_G_M_2",                                       "Dry weight biomass", "ODRYBM01",
         "Dilution_Factor",                                                      "???",      "???",
    "TOTAL_DILFACTOR_CFIN",                                                      "???",      "???"
    )



# ---- example MoF ---- 

# column_mappings <- 
    tibble::tribble(
~orig_term,                             ~uri,     ~unit,             ~unitID, ~accuracy,      ~measurementTypeID,         ~measurementMethod,
"Net_Type",                "L05/current/22/",        NA,                  NA,   NA,                   "net type",                         NA,
"Bongo Nets",        "L22/current/NETT0176/",        NA,                  NA,   NA,                           NA,                         NA, 
"Mesh_Size",         "Q01/current/Q0100015/", "microns", "P06/current/UMIC/",   NA,                  "mesh size",                         NA,
"NET_DEPTH",         "P01/current/DXPHPRST/",       "m", "P06/current/UPAA/",   NA,                  "net depth",                         NA,
"Plankton_Net_Area", "Q01/current/Q0100017/",      "m2", "P06/current/UPAA/",   NA,          "plankton net area",                         NA,
"Volume_Filtered",        "P25/current/VOL/",      "m3", "P06/current/UPAA/",   NA,            "volume filtered", "geometrically determined",
"Dilution_Factor",                        NA,      "ml", "P06/current/VVML/",   NA,            "dilution factor",                         NA,
"TOTAL_DILFACTOR_CFIN",                   NA,      "ml", "P06/current/VVML/",   NA, "Total Dilution factor CFIN",                         NA,
"Sample_Split",                           NA, "decimal", "P06/current/UPCT/",   NA,               "sample split",          "Folsom Splitter"
        )
}
```

```{r IMaRS-MoF}
# names(taxa_matched_merg)
# need:
# measurementType, measurementTypeID, measurementValue, measurementUnit, measurementAccuracy, measurementDeterminedBy, measurementMethod, measurementRemarks
def_web <- "http://vocab.nerc.ac.uk/collection/"

MoF1 <-
tibble::tribble(
~orig_term,             ~measurementType, ~measurementType_uri, ~measurementAccuracy, ~measurementUnit, ~measurementUnit_uri, ~measurementValue,
"Net_Type",                 "bongo nets", "L22/current/NETT0176/",                NA,               NA,                   NA,                NA,
"distance_m", "Length of sampling track", "P01/current/LENTRACK/",                NA,         "metres", "P06/current/ULAA/",                NA,
"net_size", "Sampling device aperture diameter", "Q01/current/Q0100012/",         NA,         "metres", "P06/current/ULAA/",                NA,
"net_area", "Sampling device aperture surface area", "Q01/current/Q0100017/", NA,   "per square metre", "P06/current/PMSQ/",                NA,
"flowmeter_in",            "flow meters", "L05/current/388/",                 NA,                   NA,                    NA,               NA,
"flowmeter_out",           "flow meters", "L05/current/388/",                 NA,                   NA,                    NA,               NA,

# 
"dillution",                      "",                     "",                 NA,         "milliliter",                    NA,               NA,
"dillution_factor",               "",                     "",                 NA,                   NA,                    NA,               NA, 
"split_amount", "Sub-sampling coefficient", "P01/current/SSAMPC01/",          NA,            "decimal",                    NA,               NA,
"splits_analyzed",                "",                     "",                 NA,                   NA,                    NA,               NA, 
# "filtered_volume_m3"
"volume_filt_cubic_m", "Sample volume (filtration) by measuring cylinder", "P01/current/VOLFMCXX/",  NA,     "per cubic metre",   "P06/current/PCUM/",               NA, 
"pipette_vol_m_l",                "",                     "",                 NA,          "milliliter",                    NA,               NA,               
# not used "mean_ind_dil_factor",            "",                     "",                 NA,                    NA,                    NA,               NA, 
"ind_m3",                "Abundance", "S06/current/S0600002/",                NA,"Number per cubic metre", "P06/current/UPMM/",               NA, 

# "ind_m3", "Abundance of mesozooplankton [Size: 200-500um] per unit volume of the water body by optical microscopy", "P01/current/ZU00M00C/", NA, "Number per cubic metre", "P06/current/UPMM/", NA, 
"number_ind_sample", "Count (in assayed sample) of biological entity specified elsewhere", "P01/current/OCOUNT01/", NA, "Count of Biological Entity", "P09/current/OCNT/",              NA, 
"tow_time_min",    "Sample Duration", "P01/current/AZDRZZ01/",                NA,             "Minutes",    "P06/current/UMIN/",              NA,
"ship_speed_knots","Speed of towing platform", "P01/current/TOWSPEED/",       NA, "Knots (nautical miles per hour)", "P06/current/UKNT/",     NA, 
"split_size",                     "",                     "",                 NA,                    NA,                     NA,              NA, 
"tow_speed_m_sec",           "Speed", "S06/current/S0600152/",                NA,   "Metres per second",    "P06/current/UVAA/",              NA, 
"mesh",     "Sampling net mesh size", "Q01/current/Q0100015/",                NA,         "Micrometres",    "P06/current/UMIC/",              NA,
"microscopy",           "microscopy",    "S04/current/S0419/",                NA,                    NA,                     NA,              NA
)  %>%
mutate(
    measurementTypeID = case_when(
        !is.na(measurementType_uri) & str_length(measurementType_uri) > 1 ~ 
            str_c(def_web, measurementType_uri),
        TRUE ~ ""
    ),
    measurementUnitID = case_when(
        !is.na(measurementUnit_uri) & str_length(measurementUnit_uri) > 0 ~ 
            str_c(def_web, measurementUnit_uri),
        TRUE ~ ""
    )
)  %>%
   select(-measurementValue & !ends_with("_uri"))
    
# after merge to measurementValue
# "Individuals per cubic metre", "P06/current/UPMM/"

# clipr::write_clip(calc)
# tibble::tribble(
#     ~date_collected, ~sample_id, ~filtered_volume_m3, ~pipette_vol_m_l, ~dillution, ~dillution_factor, ~mesh, ~date_analyzed, ~split_amount,
#        "2015-11-16",  "MR 1115",                 97L,               5L,       250L,               50L,  500L,   "2021-07-23",            2L
#     )

# http://vocab.nerc.ac.uk/collection/L05/current/22/
# might need to pivot wider first, then pivot longer

```
# Meaurement or Fact Level Info
```{r MoF}
# def_web <- "http://vocab.nerc.ac.uk/collection/"


MoF  <-
    taxa_matched_merg %>%
     left_join(event, 
              by = c("cruise_id", "site" = "locationID", "mesh", "recordedBy", 
                     "recordedByID", "basisOfRecord")
              ) %>%
    distinct(eventID, .keep_all = TRUE) %>%
    select(-c(aphiaID:recordedByID)) %>%
        mutate(
        Net_type = "bongo nets",
        microscopy = "microscopy"
    ) %>%
    
    pivot_longer(
                 cols = MoF1$orig_term[-1],
        # cols = c("split_amount", "mesh", "ind_m3"),
                 names_to = "orig_term",
                 values_to = "measurementValue",
        values_transform = list(measurementValue = as.character)
    ) %>%
    select(datasetID, eventID, orig_term, measurementValue) %>%
    left_join(MoF1, by = c("orig_term"))


# ---- MoF MBON ----
# TODO: maybe create a list for each measurement type? 
# use occurrence and event ID and the rest would be dependent on the actual
# mesurements: 
# i.e. net, mesh, area, volume filtered, etc..
# mof <- 
#     taxa_matched_merg %>%
#     left_join(event, by = c("cruise_id", "site" = "locationID", "mesh")) %>%
#     dplyr::transmute(
#         occurrenceID,
#         eventID,
#         measurementType   = "Relative abundance",
#         measurementID     = "http://vocab.nerc.ac.uk/collection/S06/current/S0600020/",
#         
#         measurementValue  = ind_m3,
#         measurementType   = "Number per cubic metre", # MOF?
#         measurementID     = "http://vocab.nerc.ac.uk/collection/S06/current/S0600002/",
#         measurementUnitID = "http://vocab.nerc.ac.uk/collection/P06/current/UPMM/", # MOF?
#     )
# 
# taxa_matched_merg %>%
#     names() %>%
#     sort()
```


```{r bd-check, result = 'hide}
compiled  <-
    reduce(list(event, location, occur, MoF), left_join) %>%
    group_by(eventID) %>%
    slice(1)
checks  <-
    compiled %>%
    bdchecks::perform_dc(.)

cat(summary_dc(checks), sep = "\n")

```

```{r save}
path <-
    here("data", "processed", "obis")

dir_create(path)

left_join(event, location) %>%
    group_by(eventID)%>%
    filter(eventID == "IMaRS_MBON_zooplankton:SV18067:stnLK:500um:2018-03-09T15:03:00") %>%
    write_csv(file = glue("{path}/event_example.csv"), na = "")

occur %>%
    group_by(eventID) %>%
    filter(eventID == "IMaRS_MBON_zooplankton:SV18067:stnLK:500um:2018-03-09T15:03:00") %>%
    write_csv(file = glue("{path}/occur_example.csv"), na = "")

MoF %>%
    group_by(eventID) %>%
    filter(eventID == "IMaRS_MBON_zooplankton:SV18067:stnLK:500um:2018-03-09T15:03:00") %>%
    write_csv(file = glue("{path}/mof_example.csv"), na = "")

```

```{r}
reduce(list(event, location, occur, MoF), left_join) %>%
    obistools::check_depth(.)

taxa_matched_merg %>%
    select(scientificName, aphiaID) %>%
    slice_head(n = 10) %>%
    transmute(
        scientificName,
    info = map(aphiaID, ~ worrms::wm_record(.x))
) %>%
  unnest(info)
reduce(list(event, location, occur), left_join) %>%
    names() 

obistools::report %>%
    View()

```
