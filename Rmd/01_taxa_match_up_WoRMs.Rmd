---
title: "Taxonomix Matchup to WoRMs"
author: "Sebastian DiGeronimo"
date: "3/2/2022"
output: html_document
---
# Load Packages
This loads any packages that are not contained in the .Rprofile.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
librarian::shelf(
    readxl, hablar, worrms, ggforce, geosphere, vroom, plotly,
    
    quiet = TRUE
    )

# set location for aphiaID list and the base of the file name
file_exprs <- file_expr(loc       = here::here("data", "metadata", "aphia_id"), 
                        file_base = "aphia_taxa")
```

# Load functions if not already
This will load the functions needed if not already contain in the search path.
```{r load-functions}
source(here("scripts", "attach_funcs.R"))
func_attach()
rm(func_attach)
```

# Load Data Sets
1. Parse all file paths in `data/raw/`. 
- Will ignore files with `~$` in front because these are usually temporary files that are opened
2. `skip_file` will check a processed file to ignore files that were previously loaded and formatted
3. Take leftover files and merge data into long format
- files contain some metadata for each sample processed and taxonomic data
```{r load-taxa-data}
# ---- find all file names and filter ----
file.taxa <- 
    fs::dir_ls(path    =  here::here("data", "raw"),
               regexp  = "^[^~]*\\.xlsx$",
               recurse = TRUE) %>%
    skip_file(., check = TRUE)

# ---- load all files into one tibble ----
taxa_data <-
    file.taxa %>%
    mutate(
    data = map(files, ~ load_data(.x, verbose = FALSE))
    ) %>%
    unnest(data)
    
head(taxa_data)
distinct(taxa_data, cruise_id, site)
```
# Merge taxanomic list and save new data
1. Loads previous master taxonomic data sheet
- This will check if it is contained in the cloud service at the root level, or create one if it doesn't exists
- If it doesn't exist, it will check the long format data for a column called taxa
- Then, it will `clean` the taxa list by removing sp., spp. and life stage information
- Next, it will use the custom function for searching scientific names in `WoRMS`
    - The base for this is `obistools::match_taxa`, but it adds the ability to type non-matched names or to use common names
- Once completed, it will save the taxa list in `data/metadata/aphia_id/` 
- It will check if there are any `NAs` if set `check = TRUE`
    - Only the `NA` rows will be rechecked again. Then it will merge with previous sheet with a new filename 

```{r aphia-ids}
# TODO: read in all files, joining with scientific names, then add more if they 
# don't exist
taxa <-
    taxa_data %>%
    select(taxa) %>%
    distinct() %>%
    merge_taxa(., 
               .file_expr = file_exprs, 
               check      = FALSE, 
               # viewer     = TRUE, 
               # .recurse   = TRUE
               )

# Check unmatched taxa names
taxa %>%
    filter(is.na(scientificName))

# uncomment if want to fix unmatched names
# taxa_unmatch(taxa,
#              lifestage,
#              .file_expr = file_exprs,
#              save_file  = TRUE,
#              viewer     = TRUE)

```

2. Merge taxa lists with long format abundance data.
- Taxa list contains `taxa_orig`, `taxa`, `lifeStage`, `scientificName`, `scientificNameID`, `match_type`

3. Save merged data in merged long format and separate samples files in 
`data/processed/` and `data/processed/ind_file_merg/` 
- If supplied `file.taxa`, it will append `processed_files.csv` (the list of 
  files) to skip in future runs in `data/metadata/`
```{r merge-data-aphia-ids}
taxa_matched_merg <- 
    right_join(taxa, taxa_data, by = c("taxa_orig" = "taxa")) %>%
    relocate(files, cruise_id, date_collected, site, .before = 1) %>%
    arrange(date_collected, site, taxa)

# save data and append processed files log
if (FALSE) {
    save_merged(taxa_matched_merg = taxa_matched_merg, 
                .taxa_file = file.taxa,
                loc = here("data", "processed"),
                ind_file = FALSE,
                append = FALSE
                )
}
```

# Push current master taxonomic sheet to cloud
1. Load most recent taxa sheet
2. Check if there any unmatched taxa
3. Push to cloud location

```{r push-to-cloud}
taxa_list  <- load_taxa_list(check = TRUE) 
no_matches <- taxa_list %>%
    filter(is.na(scientificName))

if (FALSE) {
    master_taxa_cloud(taxa_list  = taxa_list, 
                      .cloud_dir = cloud_dir, 
                      where_to   = "cloud")
}
```
# Copy Processed Files to Cloud
```{r}
# ============================================================================ #
# ---- Check if Cloud Directory is Set and Exists ----
# ============================================================================ #    
if (is.na(cloud_dir) | !dir_exists(cloud_dir)) {
    rlang::abort("Stop! You don't have a cloud directory set!")
}

# ============================================================================ #
# ---- Copy Individual Files ----
# ============================================================================ #    
if (FALSE) {
    copy_loc <- here(cloud_dir, "processed", "ind_file_merg")
    
    dir_create(copy_loc)
    
    here("data", "processed", "ind_file_merg") %>%
    dir_ls() %>%
    tibble(files = .) %>%
    mutate(base      = basename(files),
           base      = str_replace(base, "processed.*", "processed\\.csv"),
           new_files = here(copy_loc, base), 
           times = file_info(files)  %>%
                     select(birth_time)) %>%
    unnest(times) %>%
    arrange(desc(birth_time)) %>%
        
    distinct(new_files, .keep_all = TRUE) %$%

    file_copy(path = files, new_path = new_files, overwrite = TRUE)
}

# ============================================================================ #
# ---- Copy Recent Merged File ----
# ============================================================================ #    
if (FALSE) {
   copy_loc <- here(cloud_dir, "processed")
   dir_create(copy_loc)

   here("data", "processed") %>%
   dir_ls(regexp = "all_merged") %>%
   last_mod() %>%
   tibble(files = .) %>%
   mutate(base      = basename(files),
          base      = str_replace(base, "processed.*", "processed\\.csv"),
          new_files = here(copy_loc, base)) %$%   
   file_copy(path = files, new_path = new_files, overwrite = TRUE)
}
```

